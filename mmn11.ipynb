{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJcM+6TbIwnNDYgd4BZamH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SnirNehemia/OU-22961-Deep-Learning/blob/main/mmn11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "VZ741Jk6UwZC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tehstI59R4-J",
        "outputId": "0c3ef037-3b8e-43ca-d7f8-62d32ae4fbaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3, 2, 1])\n",
            "torch.Size([2, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "def my_expand_as(A,B):\n",
        "  # check which dimensions will be broadcasted\n",
        "  dimension=0\n",
        "  # while (dimension<len(A.shape) and dimension<len(B.shape) and\n",
        "  #        (A.shape[-dimension-1] == B.shape[-dimension-1]\n",
        "  #       or A.shape[-dimension-1] == 1\n",
        "  #       or B.shape[-dimension-1] == 1)):\n",
        "  while dimension<len(A.shape) and dimension<len(B.shape) or B.shape[-dimension-1] == 1:\n",
        "    dimension+=1\n",
        "    print(1)\n",
        "  print(f'{dimension=}')\n",
        "  if dimension==0: # the first dimension doesn't meet the criteria\n",
        "    raise RuntimeError(f'The size of tensor a ({A.shape[-1]}) must match the size of'\n",
        "    f'tensor b ({B.shape[-1]}) at non-singleton dimension 1')\n",
        "  while len(B.shape) > len(A.shape):\n",
        "    A = torch.stack([A]*B.shape[len(B.shape)-len(A.shape)-1],dim=0)\n",
        "  C = A\n",
        "  # print(C)\n",
        "  # print(C.shape)\n",
        "  return C\n",
        "\n",
        "A = torch.ones([2])\n",
        "B = torch.ones([10,5,2])\n",
        "\n",
        "Ar = torch.randn([2,1])\n",
        "Br = torch.randn([2,3,2,1])\n",
        "\n",
        "# Cr_mine = my_expand_as(Ar.clone(),Br)\n",
        "Cr_torch = Ar.expand_as(Br)\n",
        "print(Cr_torch.shape, Cr_mine.shape,sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Cr_torch)\n",
        "print(Cr_mine)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-0ldDc6pUFX",
        "outputId": "8b62355f-c8e8-46e7-c19b-304e5cfa7edb"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.7930,  0.7930,  0.7930],\n",
            "        [-0.6065, -0.6065, -0.6065]])\n",
            "tensor([[ 0.7930],\n",
            "        [-0.6065]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Cr_mine==Cr_torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olzEfaTGUjYR",
        "outputId": "6d589c89-7888-4fe1-c3e1-5dd7b506171d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]]],\n",
              "\n",
              "\n",
              "        [[[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]]],\n",
              "\n",
              "\n",
              "        [[[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]]],\n",
              "\n",
              "\n",
              "        [[[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]]],\n",
              "\n",
              "\n",
              "        [[[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]]],\n",
              "\n",
              "\n",
              "        [[[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]]],\n",
              "\n",
              "\n",
              "        [[[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]]],\n",
              "\n",
              "\n",
              "        [[[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]]],\n",
              "\n",
              "\n",
              "        [[[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]]],\n",
              "\n",
              "\n",
              "        [[[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]],\n",
              "\n",
              "         [[True, True],\n",
              "          [True, True]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.stack([A]*3,dim=0)\n",
        "print(a.shape)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t2OYtPwwVD3W",
        "outputId": "799bd36d-d964-4296-8eb8-a694b3fbab96"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 2])\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.stack([a]*5,dim=1)\n",
        "print(a.shape)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nnx7Q6Aa_TZ",
        "outputId": "af8f8db0-59e3-4aab-ea2f-e5770e845ed2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 5, 2])\n",
            "tensor([[[1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.]],\n",
            "\n",
            "        [[1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.]],\n",
            "\n",
            "        [[1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.],\n",
            "         [1., 1.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pJGw7eF7bN6F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}